{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import bson\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import imread\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NCORE = 2\n",
    "\n",
    "all_categories_array = np.array([])\n",
    "\n",
    "#categories to int dictionary\n",
    "categ_to_int = {}\n",
    "int_to_categ = {}\n",
    "\n",
    "#total number of items in the list\n",
    "n_train = 7069896 #from kaggle page\n",
    "n_test = 1768182 #from kaggle page\n",
    "n_example = 100 #from kaggle page\n",
    "\n",
    "all_categories_filename_format = 'allcategoriesdata_{0}.p'\n",
    "train_data_batch_file_format = 'training_batches/{0}/train_{0}_{1}_{2}.jpeg'\n",
    "test_data_batch_file_format = 'testing_batches/{0}/test_{0}_{1}_{2}.jpeg'\n",
    "\n",
    "train_category_folder_path_format = 'training_batches/{0}'\n",
    "test_category_folder_path_format = 'testing_batches/{0}'\n",
    "test_category_folder_name_format = 'folder_{0}'\n",
    "\n",
    "show_every = 10000\n",
    "\n",
    "mini_batch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_categ_to_int_dicts(data_file_path):\n",
    "    \"\"\"\n",
    "    restores categ_to_int and int_to_categ object dictionaries from saved state files if exist\n",
    "    : data_file_path: actual data file path - to represent the mode (train or train example)\n",
    "    \"\"\"\n",
    "    process_filename = data_file_path[data_file_path.rfind('/')+1:]\n",
    "    filename_suffix = process_filename.replace('.bson','')\n",
    "    categories_filename = all_categories_filename_format.format(filename_suffix)\n",
    "    \n",
    "    with open(categories_filename, 'rb') as f:\n",
    "        \n",
    "        global categ_to_int, int_to_categ\n",
    "        \n",
    "        categ_to_int, int_to_categ = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_one_hot_label(original_label, label_length, one_hot_labels):\n",
    "    \"\"\"\n",
    "    creates one hot label for a given original label value. A sub function for multi core processing of one hot encode function\n",
    "    : label_length: length of label to initialize the array\n",
    "    : one_hot_labels: the array that contains all one hot label\n",
    "    : return: void\n",
    "    \"\"\"\n",
    "    one_hot_label = np.zeros(label_length, dtype='int16')\n",
    "    one_hot_label[categ_to_int[original_label]] = 1\n",
    "    one_hot_labels.append(one_hot_label)\n",
    "\n",
    "def one_hot_encode(data_batch, n_classes):\n",
    "    \"\"\"\n",
    "    creates one hot encoded label for the given data batch using multi-core processing\n",
    "    : data_batch: the sub-section of original final training data\n",
    "    : return: array of one hot encoded label\n",
    "    \"\"\"\n",
    "    one_hot_labels = list()\n",
    "    label_length = n_classes #len(categ_to_int)\n",
    "    #print(data_batch)\n",
    "    for i in range(len(data_batch)):\n",
    "        original_label = int(data_batch[i]) # 0 - category column\n",
    "        create_one_hot_label(original_label, label_length, one_hot_labels)\n",
    "\n",
    "    one_hot_labels = np.array(list(one_hot_labels))\n",
    "    return one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load dictionaries - categ_to_int and int_to_categ from files to objects\n",
    "load_categ_to_int_dicts('data/train.bson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5270"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categ_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (180, 180, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    xmax = 255 #image max value\n",
    "    return x.astype(np.float)/float(xmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'training_batches/'\n",
    "contents = os.listdir(data_dir)\n",
    "classes = [each for each in contents if os.path.isdir(data_dir + each)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Load function done\n"
     ]
    }
   ],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"\n",
    "    loads the image from the given path, crops if it is not 180x180 and returns the image data\n",
    "    : path: image file path\n",
    "    : returns: resized image data\n",
    "    \"\"\"\n",
    "    img = imread(path)\n",
    "    img = img / 255.0\n",
    "    if (img.shape[0] == 180) & (img.shape[1] == 180):\n",
    "        return img\n",
    "    else:\n",
    "        short_edge = min(img.shape[:2])\n",
    "        yy = int((img.shape[0] - short_edge) / 2)\n",
    "        xx = int((img.shape[1] - short_edge) / 2)\n",
    "        crop_img = img[yy: yy + short_edge, xx: xx + short_edge]\n",
    "        # resize to 180, 180\n",
    "        resized_img = skimage.transform.resize(crop_img, (180, 180), mode='constant')\n",
    "        return resized_img\n",
    "\n",
    "'''Test Method below'''\n",
    "#load_image('training_batches/1000000237/train_1000000237_12600_0.jpeg')\n",
    "print('Image Load function done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_size_to_consider = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_label_mapping = 'file_label_mapping.p'\n",
    "file_path_format = '{0}/{1}/{2}'\n",
    "label_folder_format = '{0}/{1}'\n",
    "\n",
    "def fetch_filenames_labels_train(folder_path):\n",
    "    \"\"\"\n",
    "    fetches all the filenames and their labels and dumps them into a pickle files\n",
    "    : folder_path: path of the parent folder\n",
    "    : returns: void\n",
    "    \"\"\"\n",
    "    contents = os.listdir(folder_path)\n",
    "    all_labels = [each for each in contents if os.path.isdir(label_folder_format.format(folder_path, each))]\n",
    "    labels = list()\n",
    "    inputs = list()\n",
    "    for label_folder in all_labels:\n",
    "        img_files = os.listdir(label_folder_format.format(folder_path, label_folder))\n",
    "        if len(img_files) < file_size_to_consider:\n",
    "            continue\n",
    "        inputs.extend([file_path_format.format(folder_path, label_folder, each) for each in img_files])\n",
    "        labels.extend([label_folder for each in img_files])\n",
    "    pickle.dump((inputs, labels), open(file_label_mapping, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_filenames_labels_train('training_batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore_filenames_labels_train(file_path):\n",
    "    \"\"\"\n",
    "    loads the pickle file that has information of image file paths and their respective labels \n",
    "    : file_path: pickle file path\n",
    "    : returns: inputs (file paths) and labels\n",
    "    \"\"\"\n",
    "    if(os.path.exists(file_path)):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            inputs, labels = pickle.load(f)\n",
    "            return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, labels = restore_filenames_labels_train(file_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "labels_ctr = Counter(labels)\n",
    "n_classes_considered = len([ e for e,c in labels_ctr.most_common() if c >= file_size_to_consider])\n",
    "n_classes_considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_count_for_label = min([ c for e,c in labels_ctr.most_common() if c >= file_size_to_consider])\n",
    "max_input_count_for_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_label_mapping_undersampled = 'file_label_mapping_undersampled.p'\n",
    "def fetch_filenames_labels_train_undersampled(folder_path, samples_count):\n",
    "    \"\"\"\n",
    "    fetches all the filenames and their labels and dumps them into a pickle files\n",
    "    : folder_path: path of the parent folder\n",
    "    : returns: void\n",
    "    \"\"\"\n",
    "    contents = os.listdir(folder_path)\n",
    "    all_labels = [each for each in contents if os.path.isdir(label_folder_format.format(folder_path, each))]\n",
    "    labels = list()\n",
    "    inputs = list()\n",
    "    indices = np.arange(samples_count)\n",
    "    for label_folder in all_labels:\n",
    "        img_files = os.listdir(label_folder_format.format(folder_path, label_folder))\n",
    "        if len(img_files) < file_size_to_consider:\n",
    "            continue\n",
    "        #randomly select file urls\n",
    "        np.random.shuffle(indices)\n",
    "        img_files_array = np.array(img_files)\n",
    "        inputs.extend([file_path_format.format(folder_path, label_folder, each) for each in img_files_array[indices]])\n",
    "        labels.extend([label_folder for each in img_files_array[indices]])\n",
    "    pickle.dump((inputs, labels), open(file_label_mapping_undersampled, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_filenames_labels_train_undersampled('training_batches', max_input_count_for_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs, labels = restore_filenames_labels_train(file_label_mapping_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs_array = np.array(inputs)\n",
    "labels_array = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def get_training_val_test_sets(inputs_array, labels_array):\n",
    "    \n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "    train_idx, val_idx = next(splitter.split(inputs_array, labels_array))\n",
    "\n",
    "    half_val_len = int(len(val_idx)/2)\n",
    "    val_idx, test_idx = val_idx[:half_val_len], val_idx[half_val_len:]\n",
    "\n",
    "    train_x, train_y = inputs_array[train_idx], labels_array[train_idx]\n",
    "    val_x, val_y = inputs_array[val_idx], labels_array[val_idx]\n",
    "    test_x, test_y = inputs_array[test_idx], labels_array[test_idx]\n",
    "    \n",
    "    result = [[train_x, train_y], [val_x, val_y], [test_x, test_y]]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inspired by resnet50 (infact, trying to recreate resnet50)\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block, dropout=False, keep_prob=1.0, do_shortcut=False):\n",
    "    \"\"\"\n",
    "    creates an identity block. Identity layer is a layer that has no conv layer at shortcut\n",
    "    : input_tensor: input tensor\n",
    "    : kernel_size: default 3, kernel size of the middle layer\n",
    "    : filters: list of integers, filter sizes of three conv layers\n",
    "    : stage: current stage, integer, used for creating names\n",
    "    : block: current block, character, used for creating names\n",
    "    \"\"\"\n",
    "    filter1, filter2, filter3 = filters\n",
    "    bn_axis = 3\n",
    "    \n",
    "    conv_name = 'res_{0}_{1}_branch_'.format(str(stage), block)\n",
    "    bn_name = 'bn_{0}_{1}_branch_'.format(str(stage), block)\n",
    "    \n",
    "    #kernel_size is fed, strides=(1,1) default, padding=valid default\n",
    "    x = tf.layers.conv2d(input_tensor, filter1, (1,1), name=conv_name + '2a',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32)) \n",
    "    x = tf.layers.batch_normalization(x, axis=bn_axis, name=bn_name +'2a')\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filter2, kernel_size=kernel_size, padding='same', name= conv_name + '2b',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "    x = tf.layers.batch_normalization(x, axis=bn_axis, name=bn_name +'2b')\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filter3, (1,1), name=conv_name + '2c',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "    x = tf.layers.batch_normalization(x, axis=bn_axis, name=bn_name +'2c')\n",
    "    \n",
    "    if(do_shortcut):\n",
    "        x = tf.add(x, input_tensor) #short cut connection\n",
    "        \n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    if(dropout):\n",
    "        x = tf.nn.dropout(x, keep_prob=keep_prob)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), do_shortcut=False):\n",
    "    \"\"\"\n",
    "    creates an conv block. Conv block layer is a layer that has a conv layer at shortcut\n",
    "    : input_tensor: input tensor\n",
    "    : kernel_size: default 3, kernel size of the middle layer\n",
    "    : filters: list of integers, filter sizes of three conv layers\n",
    "    : stage: current stage, integer, used for creating names\n",
    "    : block: current block, character, used for creating names\n",
    "    : strides: strides that kernels take\n",
    "    \"\"\"\n",
    "    filter1, filter2, filter3 = filters\n",
    "    bn_axis = 3\n",
    "    \n",
    "    conv_name = 'res_{0}_{1}_branch_'.format(str(stage), block)\n",
    "    bn_name = 'bn_{0}_{1}_branch_'.format(str(stage), block)\n",
    "    \n",
    "    x = tf.layers.conv2d(input_tensor, filter1, (1,1), strides=strides, name=conv_name + '2a',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32)) #applied strides\n",
    "    x = tf.layers.batch_normalization(x, axis=bn_axis, name=bn_name +'2a')\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filter2, kernel_size, padding='same', name=conv_name + '2b',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "    x = tf.layers.batch_normalization(x, axis=bn_axis, name=bn_name +'2b')\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    x = tf.layers.conv2d(x, filter3, (1,1), padding='same', name=conv_name + '2c',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "    x = tf.layers.batch_normalization(x, axis=bn_axis, name=bn_name +'2c')\n",
    "    \n",
    "    if(do_shortcut):  \n",
    "        shortcut = tf.layers.conv2d(input_tensor, filter3, (1,1), strides=strides, name=conv_name + '1',  kernel_initializer = tf.truncated_normal_initializer(stddev=0.1, dtype=tf.float32))\n",
    "        shortcut = tf.layers.batch_normalization(shortcut, axis=bn_axis, name=bn_name +'1')\n",
    "        x = tf.add(x, shortcut) #short cut connection\n",
    "    \n",
    "    x = tf.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs_labels(image_shape, n_classes):\n",
    "    #prepare input tensors\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None, *image_shape], name='inputs')\n",
    "    labels = tf.placeholder(tf.float32, shape=[None, n_classes], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "    return inputs, labels, keep_prob\n",
    "    \n",
    "#inspired by resnet50 (infact, trying to recreate resnet50)\n",
    "def build_model(inputs, labels, n_classes, keep_probability):\n",
    "    bn_axis = 3\n",
    "    #prepare model\n",
    "    keep_probability = 1.0\n",
    "    \n",
    "    #paddings = [[1,0],[2,3], [3,3], [4,0]] #(3,3) zero padding 2d in keras\n",
    "    #x = tf.pad(inputs, paddings)\n",
    "    \n",
    "    x = tf.layers.conv2d(inputs, 64, (7,7), strides=(2,2), name='conv1')\n",
    "    #x = tf.layers.batch_normalization(x, axis=bn_axis, name='bn_conv1')\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.layers.max_pooling2d(x, (3,3), strides=(2,2))\n",
    "    \n",
    "    x = conv_block(x, 3, [64,64,256], stage=2, block='a', strides=(1,1), do_shortcut=True)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', dropout=False, keep_prob=keep_probability, do_shortcut=True)\n",
    "    \n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', dropout=False, keep_prob=keep_probability, do_shortcut=True)\n",
    "    \n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', do_shortcut=True)\n",
    "    #x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', do_shortcut=True)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', dropout=False, keep_prob=keep_probability, do_shortcut=True)\n",
    "    \n",
    "    #x = conv_block(x, 3, [512,512,2048], stage=5, block='a', do_shortcut=True)\n",
    "    #x = identity_block(x, 3, [512,512,2048], stage=5, block='b', do_shortcut=True)\n",
    "    #x = identity_block(x, 3, [512,512,2048], stage=5, block='c', dropout=True, keep_prob=keep_probability, do_shortcut=True)\n",
    "    \n",
    "    \n",
    "    x = tf.layers.average_pooling2d(x, (5,5), strides=(5, 5), name='avg_pool') #changed from (7,7) from original res50\n",
    "    \n",
    "    #flattening\n",
    "    image_size = x.get_shape()[1:].num_elements()\n",
    "    x = tf.reshape(x, [-1, image_size])\n",
    "    \n",
    "    logits = tf.layers.dense(x, n_classes, activation=None, name='fc5270')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size):\n",
    "    \"\"\"\n",
    "    splits x and y into n batches based on batch_size\n",
    "    : x: features set\n",
    "    : y: labels set\n",
    "    : batch_size: size of each batch \n",
    "    : returns: batches\n",
    "    \"\"\"\n",
    "    total_count = len(x)\n",
    "    batch_count = int(np.ceil(total_count / batch_size))\n",
    "    batches = list()\n",
    "    for idx in range(batch_count):\n",
    "        x_batch, y_batch = [],[]\n",
    "        if idx == batch_count-1:\n",
    "            x_batch = x[idx*batch_size:]\n",
    "            y_batch = y[idx*batch_size:]\n",
    "        else:\n",
    "            x_batch = x[idx*batch_size: (idx+1)*batch_size]\n",
    "            y_batch = y[idx*batch_size: (idx+1)*batch_size]\n",
    "        batches.append([x_batch, y_batch])\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_image_data_for_batch(x_paths):\n",
    "    \"\"\"\n",
    "    gets image data in 180x180x3 shape for given paths\n",
    "    : x_paths: list of paths to actual image files\n",
    "    : returns: np array of image data\n",
    "    \"\"\"\n",
    "    x_batch = []\n",
    "    for path in x_paths:\n",
    "        img = load_image(path)\n",
    "        x_batch.append(img)\n",
    "    return normalize(np.array(x_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_model_output(inputs, labels, learning_rate):\\n    \\n    \\n    return logits, cost, optimizer, accuracy'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def get_model_output(inputs, labels, learning_rate):\n",
    "    \n",
    "    \n",
    "    return logits, cost, optimizer, accuracy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get training sets, validation sets and test sets\n",
    "save_model_path = './saved_model'\n",
    "[train_x, train_y], [val_x, val_y], [test_x, test_y] = get_training_val_test_sets(inputs_array, labels_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_x, train_y, val_x, val_y):\n",
    "    \n",
    "    epochs = 4\n",
    "    batch_size  = 128\n",
    "    learning_rate = 0.00001\n",
    "    keep_probability = 0.75\n",
    "    \n",
    "    show_accuracy_every = 10\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        image_shape = [180, 180, 3]\n",
    "        n_classes =  len(categ_to_int) #n_classes_considered #3970 #len(categ_to_int) #5270\n",
    "        \n",
    "        inputs, labels, keep_prob = build_inputs_labels(image_shape=image_shape, n_classes=n_classes)\n",
    "    \n",
    "        logits = build_model(inputs, labels, n_classes, keep_prob)\n",
    "        logits = tf.identity(logits, name='logits') #assigning a name\n",
    "        \n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "        correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    \n",
    "        # Optimizer, Accuracy\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=1e-06 ).minimize(cost)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "    \n",
    "        # get training batches\n",
    "        batches = get_batches(train_x, train_y, batch_size=batch_size)\n",
    "        \n",
    "        val_row_count = len(val_x)\n",
    "        val_indices = np.arange(val_row_count)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            batch_i = 0\n",
    "            for batch in batches:\n",
    "                x_batch_paths = batch[0]\n",
    "                y_batch_labels = batch[1]\n",
    "                \n",
    "                batch_i += 1\n",
    "                print('Epoch: {}, Batch: {},'.format(epoch + 1, batch_i), end='')                \n",
    "                \n",
    "                x_batch = get_image_data_for_batch(x_batch_paths)\n",
    "                y_batch = one_hot_encode(data_batch=y_batch_labels, n_classes=n_classes)\n",
    "                \n",
    "                print('Executing.') \n",
    "                loss, opt = sess.run([cost, optimizer], feed_dict={inputs:x_batch, labels:y_batch, keep_prob:keep_probability})\n",
    "                \n",
    "                #print('Loss : {}, '.format(loss), end='')\n",
    "                print('Loss : {}, '.format(loss))\n",
    "                \n",
    "                if (batch_i+1) % show_accuracy_every == 0:\n",
    "                    #shuffle validation batch indices\n",
    "                    np.random.shuffle(val_indices)\n",
    "                    batch_val_indices = val_indices[:5*batch_size]\n",
    "\n",
    "                    val_x_paths = val_x[batch_val_indices]\n",
    "                    val_y_labels = val_y[batch_val_indices]\n",
    "\n",
    "                    val_x_batch = get_image_data_for_batch(val_x_paths)\n",
    "                    val_y_batch = one_hot_encode(data_batch=val_y_labels, n_classes=n_classes)\n",
    "\n",
    "                    accuracy_out = sess.run(accuracy, feed_dict={inputs:val_x_batch, labels:val_y_batch, keep_prob:1.0})\n",
    "\n",
    "                    print('accuracy : {}, '.format(accuracy_out))\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, save_model_path)\n",
    "        \n",
    "    print('training finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_x, test_y):\n",
    "    batch_size  = 128\n",
    "\n",
    "    # get training batches\n",
    "    batches = get_batches(test_x, test_y, batch_size=batch_size)\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        \n",
    "        n_classes =  len(categ_to_int) #n_classes_considered #3970 #len(categ_to_int) #5270\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('inputs:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('labels:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        test_batch_acc_total = 0\n",
    "        \n",
    "        batch_i = 0\n",
    "        for batch in batches:\n",
    "            x_batch_paths = batch[0]\n",
    "            y_batch_labels = batch[1]\n",
    "\n",
    "            batch_i += 1\n",
    "\n",
    "            print('Batch: {},'.format(batch_i), end='')\n",
    "            x_batch = get_image_data_for_batch(x_batch_paths)\n",
    "            y_batch = one_hot_encode(data_batch=y_batch_labels, n_classes=n_classes)\n",
    "            \n",
    "            print('Executing.')\n",
    "\n",
    "            accuracy_out = sess.run([loaded_acc], feed_dict={loaded_x:x_batch, loaded_y:y_batch, loaded_keep_prob:1.0})\n",
    "            print('Batch Test Accuracy:{}'.format(accuracy_out))\n",
    "            test_batch_acc_total += accuracy_out\n",
    "        \n",
    "        print('final accuracy:{}'.format(test_batch_acc_total/batch_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_file_path_mapping = 'test_file_path_mapping.p'\n",
    "test_file_path_format = '{0}/{1}/{2}'\n",
    "test_intermediate_folder_format = '{0}/{1}'\n",
    "\n",
    "test_data_dir = 'testing_batches/'\n",
    "\n",
    "def fetch_filenames_predict_test(folder_path):\n",
    "    \"\"\"\n",
    "    fetches all the filenames for final prediction test and dumps them into a pickle files\n",
    "    : folder_path: path of the parent folder\n",
    "    : returns: void\n",
    "    \"\"\"\n",
    "    contents = os.listdir(folder_path)\n",
    "    all_folders = [each for each in contents if os.path.isdir(test_intermediate_folder_format.format(folder_path, each))]\n",
    "    test_inputs = list()\n",
    "    for temp_folder in all_folders:\n",
    "        img_files = os.listdir(test_intermediate_folder_format.format(folder_path, temp_folder))\n",
    "        test_inputs.extend([test_file_path_format.format(folder_path, temp_folder, each) for each in img_files])\n",
    "    pickle.dump((test_inputs), open(test_file_path_mapping, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_filenames_predict_test(test_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def restore_filenames_predict_test(file_path):\n",
    "    \"\"\"\n",
    "    loads the pickle file that has information of image file paths and their respective labels \n",
    "    : file_path: pickle file path\n",
    "    : returns: inputs (file paths) and labels\n",
    "    \"\"\"\n",
    "    if(os.path.exists(file_path)):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            inputs = pickle.load(f)\n",
    "            return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_inputs = restore_filenames_predict_test(test_file_path_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_batches(x, batch_size):\n",
    "    \"\"\"\n",
    "    splits x into n batches based on batch_size\n",
    "    : x: test features set \n",
    "    : batch_size: size of each batch \n",
    "    : returns: batches\n",
    "    \"\"\"\n",
    "    total_count = len(x)\n",
    "    batch_count = int(np.ceil(total_count / batch_size))\n",
    "    batches = list()\n",
    "    for idx in range(batch_count):\n",
    "        x_batch = []\n",
    "        if idx == batch_count-1:\n",
    "            x_batch = x[idx*batch_size:]\n",
    "        else:\n",
    "            x_batch = x[idx*batch_size: (idx+1)*batch_size]\n",
    "        batches.append(x_batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_final_test(test_x):\n",
    "    batch_size  = 1024\n",
    "\n",
    "    # get training batches\n",
    "    batches = get_test_batches(test_x, batch_size=batch_size)\n",
    "    \n",
    "    loaded_graph = tf.Graph()\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "        \n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        \n",
    "        test_batch_acc_total = 0\n",
    "        \n",
    "        batch_i = 0\n",
    "        for batch in batches:\n",
    "            x_batch_paths = batch[0]\n",
    "\n",
    "            x_batch = get_image_data_for_batch(x_batch_paths)\n",
    "            batch_i += 1\n",
    "\n",
    "            print('Batch: {},'.format(batch_i), end='')\n",
    "            logits_out = sess.run([loaded_logits], feed_dict={loaded_x:x_batch, loaded_keep_prob:1.0})\n",
    "            pred = np.argmax(logits_out, axis=1)\n",
    "            pred_to_categ = [int_to_categ(val) for val in pred]\n",
    "            #TODO: need to fetch ids here and join it with pred and write to a file\n",
    "            \n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1,Executing.\n",
      "Loss : 286.35662841796875, \n",
      "Epoch: 1, Batch: 2,Executing.\n",
      "Loss : 173.78131103515625, \n",
      "Epoch: 1, Batch: 3,Executing.\n",
      "Loss : 111.88907623291016, \n",
      "Epoch: 1, Batch: 4,Executing.\n",
      "Loss : 82.68364715576172, \n",
      "Epoch: 1, Batch: 5,Executing.\n",
      "Loss : 53.05125427246094, \n",
      "Epoch: 1, Batch: 6,Executing.\n",
      "Loss : 36.76364517211914, \n",
      "Epoch: 1, Batch: 7,Executing.\n",
      "Loss : 25.383262634277344, \n",
      "Epoch: 1, Batch: 8,Executing.\n",
      "Loss : 18.172826766967773, \n",
      "Epoch: 1, Batch: 9,Executing.\n",
      "Loss : 15.941097259521484, \n",
      "accuracy : 0.0, \n",
      "Epoch: 1, Batch: 10,Executing.\n",
      "Loss : 13.24866771697998, \n",
      "Epoch: 1, Batch: 11,Executing.\n",
      "Loss : 11.632124900817871, \n",
      "Epoch: 1, Batch: 12,Executing.\n",
      "Loss : 10.576765060424805, \n",
      "Epoch: 1, Batch: 13,Executing.\n",
      "Loss : 9.86425495147705, \n",
      "Epoch: 1, Batch: 14,Executing.\n",
      "Loss : 9.628554344177246, \n",
      "Epoch: 1, Batch: 15,Executing.\n",
      "Loss : 9.191798210144043, \n",
      "Epoch: 1, Batch: 16,Executing.\n",
      "Loss : 9.061807632446289, \n",
      "Epoch: 1, Batch: 17,Executing.\n",
      "Loss : 8.896686553955078, \n",
      "Epoch: 1, Batch: 18,Executing.\n",
      "Loss : 8.836183547973633, \n",
      "Epoch: 1, Batch: 19,Executing.\n",
      "Loss : 8.66732406616211, \n",
      "accuracy : 0.0, \n",
      "Epoch: 1, Batch: 20,Executing.\n",
      "Loss : 8.751299858093262, \n",
      "Epoch: 1, Batch: 21,Executing.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-2b89c744e83f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-b27bd365be23>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_x, train_y, val_x, val_y)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Executing.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mkeep_probability\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[1;31m#print('Loss : {}, '.format(loss), end='')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\boopalan\\Anaconda\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\boopalan\\Anaconda\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\boopalan\\Anaconda\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\boopalan\\Anaconda\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\boopalan\\Anaconda\\envs\\dlnd-tf-lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_x, train_y, val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644382"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2849"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categ_to_int[1000018402]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5270"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categ_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'g', 'd', 'h', 'a']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list()\n",
    "b = ['a', 'b', 'g', 'd', 'h', 'e']\n",
    "a = np.arange(5)\n",
    "np.random.shuffle(a)\n",
    "list(np.array(b)[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['training_batches/1000010086/train_1000010086_1601957_0.jpeg',\n",
       "       'training_batches/1000010653/train_1000010653_23566_3.jpeg'], \n",
       "      dtype='<U59')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
